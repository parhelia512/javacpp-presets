// Targeted by JavaCPP version 1.5.13-SNAPSHOT: DO NOT EDIT THIS FILE

package org.bytedeco.onnxruntime;

import java.nio.*;
import org.bytedeco.javacpp.*;
import org.bytedeco.javacpp.annotation.*;

import static org.bytedeco.javacpp.presets.javacpp.*;
import org.bytedeco.opencl.*;
import static org.bytedeco.opencl.global.OpenCL.*;
import org.bytedeco.dnnl.*;
import static org.bytedeco.dnnl.global.dnnl.*;

import static org.bytedeco.onnxruntime.global.onnxruntime.*;


/**
 * \brief Contains functions that an OrtEp implements to specify the computation for an operator kernel.
 * @since Version 1.24.
 */
@Properties(inherit = org.bytedeco.onnxruntime.presets.onnxruntime.class)
public class OrtKernelImpl extends Pointer {
    static { Loader.load(); }
    /** Default native constructor. */
    public OrtKernelImpl() { super((Pointer)null); allocate(); }
    /** Native array allocator. Access with {@link Pointer#position(long)}. */
    public OrtKernelImpl(long size) { super((Pointer)null); allocateArray(size); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public OrtKernelImpl(Pointer p) { super(p); }
    private native void allocate();
    private native void allocateArray(long size);
    @Override public OrtKernelImpl position(long position) {
        return (OrtKernelImpl)super.position(position);
    }
    @Override public OrtKernelImpl getPointer(long i) {
        return new OrtKernelImpl((Pointer)this).offsetAddress(i);
    }

  /** Must be initialized to ORT_API_VERSION */
  public native @Cast("uint32_t") int ort_version_supported(); public native OrtKernelImpl ort_version_supported(int setter);
  /** EP must initialize to 0. Used internally by ORT. */
  public native @Cast("uint32_t") int flags(); public native OrtKernelImpl flags(int setter);

  /** \brief Computation function called to execute the kernel on an EP.
   *
   * \note Implementation of this function is required.
   *
   * @param this_ptr [in] The OrtKernelImpl instance.
   * @param context [in] The OrtKernelContext instance that provides access to the inputs and outputs.
   *
   * \snippet{doc} snippets.dox OrtStatus Return Value
   *
   * @since Version 1.24.
   */
  public native OrtStatus Compute( OrtKernelImpl this_ptr, OrtKernelContext context);

  /** \brief Called by ORT to release the OrtKernelImpl instance and its resources.
   *
   * \note Implementation of this function is required.
   *
   * @param this_ptr [in] The OrtKernelImpl instance.
   *
   * @since Version 1.24.
   */
  public static class Release_OrtKernelImpl extends FunctionPointer {
      static { Loader.load(); }
      /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
      public    Release_OrtKernelImpl(Pointer p) { super(p); }
      protected Release_OrtKernelImpl() { allocate(); }
      private native void allocate();
      public native void call( OrtKernelImpl this_ptr);
  }
  public native Release_OrtKernelImpl Release(); public native OrtKernelImpl Release(Release_OrtKernelImpl setter);

  /** \brief Optional function to pre-pack a constant tensor (i.e., a weight) to the kernel's preferred data layout.
   *
   * For example, a Conv kernel can define this function to pack input W to the channel-last data layout
   * before inference.
   *
   * Pre-packing can operate in three different modes: no pre-packing mode, sharing mode, and non-sharing mode.
   *    1) No pre-packing mode: The kernel can forgo any weight pre-packing for the given {@code input_index} by setting
   *                            {@code is_packed} to false and returning a successful OrtStatus. In this mode, the kernel's
   *                            OrtKernelImpl::SetSharedPrePackedWeight() function is not called for that specific
   *                            {@code input_index}.
   *    2) Sharing mode: Sharing is allowed if the {@code prepacked_weight_cache} argument is not NULL and the EP stores
   *                     weight data in CPU-accessible memory. In this case, the kernel can optionally choose
   *                     to share the packed weight with other kernels that use the same weight
   *                     (compared by content hash). To do so, the kernel must allocate the packed weight with the
   *                     provided {@code allocator}, then it stores the packed weight data into {@code prepacked_weight_cache}
   *                     via SharedPrePackedWeightCache_StoreWeightData(), sets {@code is_packed} to true, and returns a
   *                     successful OrtStatus. ORT will subsequently call OrtKernelImpl::SetSharedPrePackedWeight()
   *                     to provide this kernel with the actual shared weight data, whose memory location could
   *                     differ (i.e., if shared data was allocated by a previously processed kernel).
   *    3) Non-sharing mode: In non-sharing mode, the {@code prepacked_weight_cache} argument is ignored. In this mode,
   *                         the implementation allocates the packed data with the provided {@code allocator}, sets
   *                         {@code is_packed} to true, and returns a successful OrtStatus. The kernel is ultimately
   *                         responsible for releasing the packed data for the weight with {@code allocator}.
   *                         ORT may release the original (unpacked) weight, which must not be accessed in
   *                         OrtKernelImpl::Compute(). Note that in this mode, the kernel's
   *                         OrtKernelImpl::SetSharedPrePackedWeight() function is not called by ORT for that specific
   *                         {@code input_index}.
   *
   * \note This function is based on the internal OpKernel::PrePack() virtual function used within ORT.
   *
   * @param this_ptr [in] The OrtKernelImpl instance.
   * @param tensor [in] The OrtValue instance representing the constant tensor (weight). Do not cache in the kernel.
   * @param input_index [in] The input index of the tensor in this kernel.
   * @param allocator [in] Allocator for allocating the pre-packed data. Its use is required in sharing mode and
   *                      recommended, but not required, in the non-sharing mode. This will be an allocator set by
   *                      the application for the session/environment (e.g., via CreateAndRegisterAllocator[V2]
   *                      or RegisterAllocator), or an allocator on the OrtEpDevice (read-only or default) otherwise.
   *                      The allocator remains valid throughout the lifetime of the OrtKernelImpl instance.
   * @param prepacked_weight_cache [in] May be NULL. If not NULL, the kernel may choose to share a packed weight by
   *                                   first storing it in the OrtSharedPrePackedWeightCache instance and then
   *                                   receiving the actual shared weight data in the call to
   *                                   OrtKernelImpl::SetSharedPrePackedWeight(). See the above description for
   *                                   "sharing mode".
   * @param is_packed [out] Output parameter that the implementation sets to true if the kernel packed the tensor data.
   *
   * \snippet{doc} snippets.dox OrtStatus Return Value
   *
   * \note Implementation of this function is optional. If not implemented (set to NULL), ORT assumes the kernel
   *       does not pre-pack weight data (i.e., {@code is_packed} defaults to false).
   *
   * @since Version 1.24.
   */
  public native OrtStatus PrePackWeight( OrtKernelImpl this_ptr, @Const OrtValue tensor,
                    int input_index, OrtAllocator allocator,
                    OrtSharedPrePackedWeightCache prepacked_weight_cache, @Cast("bool*") BoolPointer is_packed);
  public native OrtStatus PrePackWeight( OrtKernelImpl this_ptr, @Const OrtValue tensor,
                    int input_index, OrtAllocator allocator,
                    OrtSharedPrePackedWeightCache prepacked_weight_cache, @Cast("bool*") boolean[] is_packed);

  /** \brief Optional function that receives data for a shared pre-packed weight from ORT.
   *
   * ORT calls this function after calling OrtKernelImpl::PrePackWeight for a specific {@code input_index} if:
   *   - OrtKernelImpl::PrePackWeight set the output parameter {@code is_packed} to true.
   *   - OrtKernelImpl::PrePackWeight stored weight data to share into the provided OrtSharedPrePackedWeightCache
   *     parameter ({@code prepacked_weight_cache}) via the API SharedPrePackedWeightCache_StoreWeightData.
   *
   * Refer to the description of the "sharing-mode" in the documentation for OrtKernelImpl::PrePackWeight().
   *
   * \note ORT will not call this function for an {@code input_index} that a previous call to
   *       OrtKernelImpl::PrePackWeight() did not elect to pre-pack and share.
   *
   * \note This function is based on the internal OpKernel::UseSharedPrePackedBuffers() virtual function used
   *       within ORT.
   *
   * @param this_ptr [in] The OrtKernelImpl instance.
   * @param buffer_data_ptrs [in] An array of buffer data pointers that collectively hold the pre-packed data for a
   *                             single shared weight. The buffers are provided in the same order and with the same
   *                             contents (in a potentially different memory location) as the buffers
   *                             passed into SharedPrePackedWeightCache_StoreWeightData() within the
   *                             OrtKernelImpl::PrePackWeight() call for the same {@code input_index}.
   * @param buffer_data_sizes [in] An array of buffer byte sizes, one per element in {@code buffer_data_ptrs}.
   * @param num_buffers [in] The number of buffers used to store the data for the shared pre-packed weight.
   *                        Specifies the number of elements in the {@code buffer_data_ptrs} and {@code buffer_data_sizes} arrays.
   * @param input_index [in] The input index of the tensor in this kernel. This index identifies the identity of
   *                        the weight.
   *
   * \snippet{doc} snippets.dox OrtStatus Return Value
   *
   * \note Implementation of this function is generally optional. It is only required if OrtKernelImpl::PrePack()
   *       elects to share pre-packed weights.
   *
   * @since Version 1.24.
   */
  public native OrtStatus SetSharedPrePackedWeight( OrtKernelImpl this_ptr,
                    @Cast("const void*const*") PointerPointer buffer_data_ptrs,
                    @Cast("const size_t*") SizeTPointer buffer_data_sizes,
                    @Cast("size_t") long num_buffers, int input_index);
  public native OrtStatus SetSharedPrePackedWeight( OrtKernelImpl this_ptr,
                    @Cast("const void*const*") @ByPtrPtr Pointer buffer_data_ptrs,
                    @Cast("const size_t*") SizeTPointer buffer_data_sizes,
                    @Cast("size_t") long num_buffers, int input_index);
}
